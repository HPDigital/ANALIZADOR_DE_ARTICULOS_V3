{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12dad0ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# import fitz  # PyMuPDF\n",
    "\n",
    "# client = OpenAI(api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "# def extraer_texto_pdf(ruta_pdf):\n",
    "#     # Abrir el documento PDF\n",
    "#     documento = fitz.open(ruta_pdf)\n",
    "    \n",
    "#     # Recopilar el texto de cada página\n",
    "#     texto_completo = \"\"\n",
    "#     for pagina in documento:\n",
    "#         texto_completo += pagina.get_text()\n",
    "    \n",
    "#     # Cerrar el documento\n",
    "#     documento.close()\n",
    "#     return texto_completo\n",
    "\n",
    "# def analyze_article(texto_completo, client):\n",
    "#     print(\"Iniciando el análisis del artículo científico.\")\n",
    "    \n",
    "#     steps = [\n",
    "#         (\"titulo_articulo\", \"Cual es el titulo del artículo\"),\n",
    "#         (\"Autor_articulo\", \"Quienes son los autores de este artículo\"),\n",
    "#         (\"Objetivo_geenral_articulo\", \"Cual es el enunciado del objetivo general de este artículo\"),\n",
    "#         (\"base teorica\", \"¿Cuáles son las bases teorícas sobre las cuales se basa el artículo de investigación?\"),\n",
    "#         (\"Metodologia\", \"¿Cuál es la metodología con la que trabaja este artiíclo de investigación?\"),\n",
    "#         (\"Herramientas\", \"¿Con que herraminetas de ivestigación se trabaja esta investigación\"),\n",
    "#         (\"Muestra\", \"¿Que y cuantos utiliza como muestra para la investigacion\"),\n",
    "#         (\"Resultados\", \"¿Que resultados se obtiene en la investigación?\"),\n",
    "#         (\"Conclusiones\", \"Cuales son las conclusiones de esta ivestigación?\"),\n",
    "#         (\"Conceptos_clave\", \" ¿Cuales son los conceptos clave que aborda el artículo?\")\n",
    "#     ]\n",
    "\n",
    "#     for step_function, description in steps:\n",
    "#         print(f\"\\n{description}\")\n",
    "        \n",
    "#         response = client.chat.completions.create(\n",
    "#             model=\"gpt-4o-2024-08-06\", \n",
    "#             messages=[{\"role\": \"system\", \"content\": description},\n",
    "#                       {\"role\": \"user\", \"content\": texto_completo}],\n",
    "#             max_tokens=1024\n",
    "#         )\n",
    "        \n",
    "#         # Asegurarse de que la respuesta tenga una estructura \n",
    "#         if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "#             # Accede directamente al atributo 'content' del mensaje\n",
    "#             message_content = response.choices[0].message.content.strip()\n",
    "#             print(message_content)\n",
    "#         else:\n",
    "#             print(\"Error: No se obtuvieron resultados de la respuesta.\")\n",
    "\n",
    "\n",
    "# ruta_del_pdf = r\"C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado del sector automotriz como herramienta para toma de decisiones empresariales.pdf\"\n",
    "# texto_completo = extraer_texto_pdf(ruta_del_pdf)\n",
    "# analisis= analyze_article(texto_completo, client)\n",
    "# print(analisis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7d1de-eaea-4818-b065-2d93c403c027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfdae96-ed1d-4f8a-9e75-f3b9ef0481a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# import fitz  # PyMuPDF\n",
    "# from docx import Document\n",
    "# import os\n",
    "\n",
    "# client = OpenAI(api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "# def extraer_texto_pdf(ruta_pdf):\n",
    "#     # Abrir el documento PDF\n",
    "#     documento = fitz.open(ruta_pdf)\n",
    "    \n",
    "#     # Recopilar el texto de cada página\n",
    "#     texto_completo = \"\"\n",
    "#     for pagina in documento:\n",
    "#         texto_completo += pagina.get_text()\n",
    "    \n",
    "#     # Cerrar el documento\n",
    "#     documento.close()\n",
    "#     return texto_completo\n",
    "\n",
    "# def analyze_article(texto_completo, client):\n",
    "#     print(\"Iniciando el análisis del artículo científico.\")\n",
    "    \n",
    "#     steps = [\n",
    "#         (\"Título del artículo\", \"¿Cuál es el título del artículo?\"),\n",
    "#         (\"Autores del artículo\", \"¿Quiénes son los autores de este artículo?\"),\n",
    "#         (\"Objetivo general del artículo\", \"¿Cuál es el enunciado del objetivo general de este artículo?\"),\n",
    "#         (\"Bases teóricas\", \"¿Cuáles son las bases teóricas sobre las cuales se basa el artículo de investigación?\"),\n",
    "#         (\"Metodología\", \"¿Cuál es la metodología con la que trabaja este artículo de investigación?\"),\n",
    "#         (\"Herramientas\", \"¿Con qué herramientas de investigación se trabaja en esta investigación?\"),\n",
    "#         (\"Muestra\", \"¿Qué y cuántos utiliza como muestra para la investigación?\"),\n",
    "#         (\"Resultados\", \"¿Qué resultados se obtienen en la investigación?\"),\n",
    "#         (\"Conclusiones\", \"¿Cuáles son las conclusiones de esta investigación?\"),\n",
    "#         (\"Conceptos clave\", \"¿Cuáles son los conceptos clave que aborda el artículo?\")\n",
    "#     ]\n",
    "\n",
    "#     # Crear un nuevo documento Word\n",
    "#     document = Document()\n",
    "\n",
    "#     for step_name, description in steps:\n",
    "#         print(f\"\\n{description}\")\n",
    "        \n",
    "#         response = client.chat.completions.create(\n",
    "#             model=\"gpt-4o-2024-08-06\", \n",
    "#             messages=[{\"role\": \"system\", \"content\": description},\n",
    "#                       {\"role\": \"user\", \"content\": texto_completo}],\n",
    "#             max_tokens=1024\n",
    "#         )\n",
    "        \n",
    "#         # Asegurarse de que la respuesta tenga una estructura \n",
    "#         if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "#             # Accede directamente al atributo 'content' del mensaje\n",
    "#             message_content = response.choices[0].message.content.strip()\n",
    "#             print(message_content)\n",
    "            \n",
    "#             # Añadir el análisis al documento Word\n",
    "#             document.add_heading(step_name, level=1)\n",
    "#             document.add_paragraph(message_content)\n",
    "#         else:\n",
    "#             print(\"Error: No se obtuvieron resultados de la respuesta.\")\n",
    "    \n",
    "#     return document\n",
    "\n",
    "# def guardar_documento(document, ruta_pdf):\n",
    "#     # Obtener el nombre del archivo PDF sin la extensión\n",
    "#     nombre_archivo = os.path.splitext(os.path.basename(ruta_pdf))[0]\n",
    "    \n",
    "#     # Crear la ruta del archivo Word con el mismo nombre y en la misma carpeta\n",
    "#     ruta_word = os.path.join(os.path.dirname(ruta_pdf), f\"{nombre_archivo}.docx\")\n",
    "    \n",
    "#     # Guardar el documento Word\n",
    "#     document.save(ruta_word)\n",
    "#     print(f\"Documento guardado en: {ruta_word}\")\n",
    "\n",
    "# ruta_del_pdf = r\"C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado del sector automotriz como herramienta para toma de decisiones empresariales.pdf\"\n",
    "# texto_completo = extraer_texto_pdf(ruta_del_pdf)\n",
    "# document = analyze_article(texto_completo, client)\n",
    "# guardar_documento(document, ruta_del_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a5f4d-26ff-4792-8166-94131e16d777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0840eb41-9531-4119-8228-f87c2d10be82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado del sector automotriz como herramienta para toma de decisiones empresariales.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado del sector automotriz como herramienta para toma de decisiones empresariales.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado para la implementación de un fast food de wraps de comida criolla en lima norte.pdf\n",
      "Iniciando el análisis del artículo científico.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32028. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 89\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Ruta del directorio donde están los archivos PDF\u001b[39;00m\n\u001b[0;32m     88\u001b[0m directorio_pdfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDIPLOMADO INVESTIGACION CIENTIFICA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMODULO 2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrabajo fin de modulo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mARTICULOS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 89\u001b[0m procesar_todos_los_pdfs(directorio_pdfs)\n",
      "Cell \u001b[1;32mIn[4], line 84\u001b[0m, in \u001b[0;36mprocesar_todos_los_pdfs\u001b[1;34m(directorio)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcesando archivo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruta_pdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m texto_completo \u001b[38;5;241m=\u001b[39m extraer_texto_pdf(ruta_pdf)\n\u001b[1;32m---> 84\u001b[0m document \u001b[38;5;241m=\u001b[39m analyze_article(texto_completo, client)\n\u001b[0;32m     85\u001b[0m guardar_documento(document, ruta_pdf)\n",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m, in \u001b[0;36manalyze_article\u001b[1;34m(texto_completo, client)\u001b[0m\n\u001b[0;32m     38\u001b[0m document \u001b[38;5;241m=\u001b[39m Document()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_name, description \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#print(f\"\\n{description}\")\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     44\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-2024-08-06\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     45\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: description},\n\u001b[0;32m     46\u001b[0m                   {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: texto_completo}],\n\u001b[0;32m     47\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m\n\u001b[0;32m     48\u001b[0m     )\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# Asegurarse de que la respuesta tenga una estructura \u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;66;03m# Accede directamente al atributo 'content' del mensaje\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:668\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    667\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    669\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    671\u001b[0m             {\n\u001b[0;32m    672\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    673\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    674\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    675\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    676\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    677\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    678\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    679\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    680\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    681\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    682\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    683\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    687\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    688\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    689\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    690\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    691\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    692\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    693\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    694\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    695\u001b[0m             },\n\u001b[0;32m    696\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    697\u001b[0m         ),\n\u001b[0;32m    698\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    699\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    700\u001b[0m         ),\n\u001b[0;32m    701\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    702\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    703\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    704\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    937\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    938\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    939\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    940\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    941\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    942\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1025\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1024\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1026\u001b[0m         input_options,\n\u001b[0;32m   1027\u001b[0m         cast_to,\n\u001b[0;32m   1028\u001b[0m         retries,\n\u001b[0;32m   1029\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1030\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1031\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1032\u001b[0m     )\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1074\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1076\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1077\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1078\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1079\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1080\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1025\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1024\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1026\u001b[0m         input_options,\n\u001b[0;32m   1027\u001b[0m         cast_to,\n\u001b[0;32m   1028\u001b[0m         retries,\n\u001b[0;32m   1029\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1030\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1031\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1032\u001b[0m     )\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1074\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1076\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1077\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1078\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1079\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1080\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1040\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1039\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1043\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1044\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1049\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32028. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# ESTE FUNCIONA BIEN PARA ARTICULOS CORTOS\n",
    "\n",
    "from openai import OpenAI\n",
    "import fitz  # PyMuPDF\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "def extraer_texto_pdf(ruta_pdf):\n",
    "    # Abrir el documento PDF\n",
    "    documento = fitz.open(ruta_pdf)\n",
    "    \n",
    "    # Recopilar el texto de cada página\n",
    "    texto_completo = \"\"\n",
    "    for pagina in documento:\n",
    "        texto_completo += pagina.get_text()\n",
    "    \n",
    "    # Cerrar el documento\n",
    "    documento.close()\n",
    "    return texto_completo\n",
    "\n",
    "def analyze_article(texto_completo, client):\n",
    "    print(\"Iniciando el análisis del artículo científico.\")\n",
    "    \n",
    "    steps = [\n",
    "        (\"Título del artículo\", \"¿Cuál es el título del artículo?\"),\n",
    "        (\"Autores del artículo\", \"¿Quiénes son los autores de este artículo?\"),\n",
    "        (\"Objetivo general del artículo\", \"¿Cuál es el enunciado del objetivo general de este artículo?\"),\n",
    "        (\"Bases teóricas\", \"¿Cuáles son las bases teóricas sobre las cuales se basa el artículo de investigación?\"),\n",
    "        (\"Metodología\", \"¿Cuál es la metodología con la que trabaja este artículo de investigación?\"),\n",
    "        (\"Herramientas\", \"¿Con qué herramientas de investigación se trabaja en esta investigación?\"),\n",
    "        (\"Muestra\", \"¿Qué y cuántos utiliza como muestra para la investigación?\"),\n",
    "        (\"Resultados\", \"¿Qué resultados se obtienen en la investigación?\"),\n",
    "        (\"Conclusiones\", \"¿Cuáles son las conclusiones de esta investigación?\"),\n",
    "        (\"Conceptos clave\", \"¿Cuáles son los conceptos clave que aborda el artículo?\")\n",
    "    ]\n",
    "\n",
    "    # Crear un nuevo documento Word\n",
    "    document = Document()\n",
    "\n",
    "    for step_name, description in steps:\n",
    "        #print(f\"\\n{description}\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-2024-08-06\", \n",
    "            messages=[{\"role\": \"system\", \"content\": description},\n",
    "                      {\"role\": \"user\", \"content\": texto_completo}],\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        \n",
    "        # Asegurarse de que la respuesta tenga una estructura \n",
    "        if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "            # Accede directamente al atributo 'content' del mensaje\n",
    "            message_content = response.choices[0].message.content.strip()\n",
    "            #print(message_content)\n",
    "            \n",
    "            # Añadir el análisis al documento Word\n",
    "            document.add_heading(step_name, level=1)\n",
    "            document.add_paragraph(message_content)\n",
    "        else:\n",
    "            print(\"Error: No se obtuvieron resultados de la respuesta.\")\n",
    "    \n",
    "    return document\n",
    "\n",
    "def guardar_documento(document, ruta_pdf):\n",
    "    # Obtener el nombre del archivo PDF sin la extensión\n",
    "    nombre_archivo = os.path.splitext(os.path.basename(ruta_pdf))[0]\n",
    "    \n",
    "    # Crear la ruta del archivo Word con el mismo nombre y en la misma carpeta\n",
    "    ruta_word = os.path.join(os.path.dirname(ruta_pdf), f\"{nombre_archivo}.docx\")\n",
    "    \n",
    "    # Guardar el documento Word\n",
    "    document.save(ruta_word)\n",
    "    print(f\"Documento guardado en: {ruta_word}\")\n",
    "\n",
    "def procesar_todos_los_pdfs(directorio):\n",
    "    # Listar todos los archivos PDF en el directorio\n",
    "    archivos_pdf = [f for f in os.listdir(directorio) if f.endswith('.pdf')]\n",
    "    \n",
    "    for archivo_pdf in archivos_pdf:\n",
    "        ruta_pdf = os.path.join(directorio, archivo_pdf)\n",
    "        print(f\"Procesando archivo: {ruta_pdf}\")\n",
    "        \n",
    "        texto_completo = extraer_texto_pdf(ruta_pdf)\n",
    "        document = analyze_article(texto_completo, client)\n",
    "        guardar_documento(document, ruta_pdf)\n",
    "\n",
    "# Ruta del directorio donde están los archivos PDF\n",
    "directorio_pdfs = r\"C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\"\n",
    "procesar_todos_los_pdfs(directorio_pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509e8c30-fbee-429f-b820-41507b5f2777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado del sector automotriz como herramienta para toma de decisiones empresariales.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado del sector automotriz como herramienta para toma de decisiones empresariales.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado para la implementación de un fast food de wraps de comida criolla en lima norte.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Error durante el análisis de Título del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32028. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Autores del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32030. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Objetivo general del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32035. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Bases teóricas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32042. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Metodología: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32039. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Herramientas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32038. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Muestra: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32035. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Resultados: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32032. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conclusiones: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32033. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conceptos clave: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 32034. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Estudio de mercado para la implementación de un fast food de wraps de comida criolla en lima norte.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Factores y variables relevantes que contribuyen al crecimiento empresarial de microempresas restaurantes fast food en Lima Metropolitana casos múltiples.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Error durante el análisis de Título del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68740. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Autores del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68742. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Objetivo general del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68747. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Bases teóricas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68754. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Metodología: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68751. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Herramientas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68750. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Muestra: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68747. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Resultados: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68744. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conclusiones: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68745. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conceptos clave: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 68746. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Factores y variables relevantes que contribuyen al crecimiento empresarial de microempresas restaurantes fast food en Lima Metropolitana casos múltiples.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Importancia del diagnóstico situacional de la empresa.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Importancia del diagnóstico situacional de la empresa.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\La investigación de mercado impacto que genera en la toma de decisiones.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\La investigación de mercado impacto que genera en la toma de decisiones.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Mercado itinerante y su relación con el incremento del margen de utilidad de los productores agropecuarios en tiempos de pandemiacovid-19, Huánuco, 2021.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Error durante el análisis de Título del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30500. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Autores del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30502. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Objetivo general del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30507. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Bases teóricas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30513. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Metodología: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30511. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Herramientas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30510. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Muestra: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30506. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Resultados: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30504. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conclusiones: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30504. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conceptos clave: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 30505. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Mercado itinerante y su relación con el incremento del margen de utilidad de los productores agropecuarios en tiempos de pandemiacovid-19, Huánuco, 2021.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Plan de negocio de Orange Bamboo. Un restaurante de comida Fast-Casual en Madrid -  Saez Barbero, Jaime.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Error durante el análisis de Título del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37050. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Autores del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37052. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Objetivo general del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37057. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Bases teóricas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37063. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Metodología: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37061. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Herramientas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37060. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Muestra: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37056. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Resultados: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37054. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conclusiones: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37054. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conceptos clave: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 37055. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Plan de negocio de Orange Bamboo. Un restaurante de comida Fast-Casual en Madrid -  Saez Barbero, Jaime.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Plan de negocios para crear una empresa de elaboración y comercialización de especialidades fast food móvil en la parroquia de calderón.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Error durante el análisis de Título del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67000. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Autores del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67002. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Objetivo general del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67007. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Bases teóricas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67014. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Metodología: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67011. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Herramientas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67010. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Muestra: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67007. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Resultados: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67004. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conclusiones: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67005. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conceptos clave: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 67006. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Plan de negocios para crear una empresa de elaboración y comercialización de especialidades fast food móvil en la parroquia de calderón.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Puesta en marcha de un Fast Food saludable en base a postres en el distrito de La Molina.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Error durante el análisis de Título del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79007. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Autores del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79009. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Objetivo general del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79013. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Bases teóricas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79020. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Metodología: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79017. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Herramientas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79017. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Muestra: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79013. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Resultados: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79010. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conclusiones: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79011. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conceptos clave: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 79012. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Puesta en marcha de un Fast Food saludable en base a postres en el distrito de La Molina.docx\n",
      "Procesando archivo: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Relación de la innovación y el desempeño organizacional de los restaurantes fast food en san isidro 2019.pdf\n",
      "Iniciando el análisis del artículo científico.\n",
      "Error durante el análisis de Título del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44665. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Autores del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44668. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Objetivo general del artículo: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44672. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Bases teóricas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44679. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Metodología: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44676. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Herramientas: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44675. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Muestra: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44672. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Resultados: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44669. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conclusiones: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44670. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error durante el análisis de Conceptos clave: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-Myatdmn3N5aHc2GuCerePIPU on tokens per min (TPM): Limit 30000, Requested 44671. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Documento guardado en: C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\\Relación de la innovación y el desempeño organizacional de los restaurantes fast food en san isidro 2019.docx\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import fitz  # PyMuPDF\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "def extraer_texto_pdf(ruta_pdf):\n",
    "    documento = fitz.open(ruta_pdf)\n",
    "    texto_completo = \"\"\n",
    "    for pagina in documento:\n",
    "        texto_completo += pagina.get_text()\n",
    "    documento.close()\n",
    "    return texto_completo\n",
    "\n",
    "def analyze_article(texto_completo, client):\n",
    "    print(\"Iniciando el análisis del artículo científico.\")\n",
    "    \n",
    "    steps = [\n",
    "        (\"Título del artículo\", \"¿Cuál es el título del artículo?\"),\n",
    "        (\"Autores del artículo\", \"¿Quiénes son los autores de este artículo?\"),\n",
    "        (\"Objetivo general del artículo\", \"¿Cuál es el enunciado del objetivo general de este artículo?\"),\n",
    "        (\"Bases teóricas\", \"¿Cuáles son las bases teóricas sobre las cuales se basa el artículo de investigación?\"),\n",
    "        (\"Metodología\", \"¿Cuál es la metodología con la que trabaja este artículo de investigación?\"),\n",
    "        (\"Herramientas\", \"¿Con qué herramientas de investigación se trabaja en esta investigación?\"),\n",
    "        (\"Muestra\", \"¿Qué y cuántos utiliza como muestra para la investigación?\"),\n",
    "        (\"Resultados\", \"¿Qué resultados se obtienen en la investigación?\"),\n",
    "        (\"Conclusiones\", \"¿Cuáles son las conclusiones de esta investigación?\"),\n",
    "        (\"Conceptos clave\", \"¿Cuáles son los conceptos clave que aborda el artículo?\")\n",
    "    ]\n",
    "\n",
    "    document = Document()\n",
    "\n",
    "    for step_name, pregunta in steps:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-2024-08-06\",\n",
    "                messages=[{\"role\": \"system\", \"content\": pregunta},\n",
    "                          {\"role\": \"user\", \"content\": texto_completo}],\n",
    "                max_tokens=1024\n",
    "            )\n",
    "            \n",
    "            if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "                message_content = response.choices[0].message.content.strip()\n",
    "                document.add_heading(step_name, level=1)\n",
    "                document.add_paragraph(message_content)\n",
    "            else:\n",
    "                print(\"Error: No se obtuvieron resultados de la respuesta.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error durante el análisis de {step_name}: {e}\")\n",
    "            pass  # Pasar al siguiente paso o artículo en caso de error\n",
    "    \n",
    "    return document\n",
    "\n",
    "def guardar_documento(document, ruta_pdf):\n",
    "    nombre_archivo = os.path.splitext(os.path.basename(ruta_pdf))[0]\n",
    "    ruta_word = os.path.join(os.path.dirname(ruta_pdf), f\"{nombre_archivo}.docx\")\n",
    "    document.save(ruta_word)\n",
    "    print(f\"Documento guardado en: {ruta_word}\")\n",
    "\n",
    "def procesar_todos_los_pdfs(directorio):\n",
    "    archivos_pdf = [f for f in os.listdir(directorio) if f.endswith('.pdf')]\n",
    "    \n",
    "    for archivo_pdf in archivos_pdf:\n",
    "        ruta_pdf = os.path.join(directorio, archivo_pdf)\n",
    "        print(f\"Procesando archivo: {ruta_pdf}\")\n",
    "        \n",
    "        try:\n",
    "            texto_completo = extraer_texto_pdf(ruta_pdf)\n",
    "            document = analyze_article(texto_completo, client)\n",
    "            guardar_documento(document, ruta_pdf)\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando el archivo {ruta_pdf}: {e}\")\n",
    "            pass  # Pasar al siguiente archivo en caso de error\n",
    "\n",
    "# Ruta del directorio donde están los archivos PDF\n",
    "directorio_pdfs = r\"C:\\Users\\HP\\Desktop\\DIPLOMADO INVESTIGACION CIENTIFICA\\MODULO 2\\trabajo fin de modulo\\ARTICULOS\"\n",
    "procesar_todos_los_pdfs(directorio_pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eaa604-b899-433d-ac11-02cff99b63f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
